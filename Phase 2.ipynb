{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 - Cleaning and Initial Analysis of Anime data\n",
    "Michelle Yang & Rachel Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection/description\n",
    "--------------------------------------------------------------------\n",
    "All datasets are downloaded from Kaggle. Kaggle user-collected data from official MyAnimeList (MAL) API and unofficial Jikan API. \n",
    "\n",
    "Data sets collected have various information updated to one month ago or three months ago. These datasets were created from user interest and not funded by any organization.\n",
    "\n",
    "Observations are for each anime and each user on MAL. Attributes for anime data include anime ID as assigned by MAL, title of anime, genre, aired year, popularity, and ranking. Attributes for user data include user ID (datasets varied for assignment, one is creator assigned, others are MAL assigned), their reviews for various animes, their scores for animes, and what they have on their anime lists. Missing information is filled in with data from older datasets. \n",
    "\n",
    "User information from the website were scraped using API by the dataset creators which users were probably not aware. The information scraped is publicy provided by the user. \n",
    "\n",
    "### Raw source data\n",
    "--------------------------------------------------------------------\n",
    "#### Compiled individual datasets: \n",
    "\n",
    "https://drive.google.com/drive/folders/1I5uVgBwEKWqfPn5RqCgdo9Cxfn2i6Th9?usp=sharing\n",
    "\n",
    "#### Individual datasets links:\n",
    "\n",
    "https://www.kaggle.com/qvinhdo/myanimelist?select=mal_db.dump:\n",
    "- MAL_anime_sept20.csv \n",
    "- user_watches_sept20.csv \n",
    "- usersID_sept20.csv\n",
    "    \n",
    "https://www.kaggle.com/marlesson/myanimelist-dataset-animes-profiles-reviews?select=reviews.csv\n",
    "\n",
    "- animes_marlesson_may20.csv\n",
    "- profiles_marlesson_may20.csv\n",
    "- reviews_marlesson_may20.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Questions\n",
    "1. What are the genre preferences for each gender? Do they play into stereotypes?\n",
    "2. Which animes are most favorited and why? \n",
    "3. What time period were anime most popular among people?\n",
    "4. What are the most popular anime aired each year?\n",
    "5. What genres are most released in which season?\n",
    "6. Which animes are the top rated animes? Why are they top rated?\n",
    "7. Which anime are most users currently watching/on hold/dropped/planning to watch? Why might they be the most dropped/currently watching?\n",
    "8. What is the age range of users watching different genres and certain animes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the main anime CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anime_data = pd.read_csv(\"animes_marlesson_jan20.csv\")\n",
    "print(\"Number of Columns in Original Data: \" + str(len(anime_data.columns)))\n",
    "print(\"Number of Observations in Original Data: \" + str(len(anime_data)))\n",
    "anime_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data by Deleting and Renaming Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleted columns like img_url and link because it's not relevant to our data analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_data = anime_data.drop(columns = ['img_url', 'link'])\n",
    "anime_data = anime_data.rename(columns = {'score':'rating'}) \n",
    "print(\"Number of Columns After Cleaning Data: \" + str(len(anime_data.columns)))\n",
    "print(\"Number of Observations After Cleaning Data: \" + str(len(anime_data)))\n",
    "anime_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Number of Anime Aired Per Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we hope to analyze the number of anime that is aired per year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset does not contain a column with only the year, so we first extracted the initial airing year from each observation in the column \"aired\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that converts aired to first aired year \n",
    "def extract_year(dataframe):\n",
    "    aired_years = []\n",
    "    for dates in dataframe['aired']:\n",
    "        start = dates.index(\",\") + 2 \n",
    "        year = dates[start:start+4] #gets the first year  \n",
    "        aired_years.append(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then appended a new column onto the anime_data dataset that contains just the year in which the anime was originally aired: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding a new column to represent the aired year \n",
    "# Cases: month, year ; Not available ; just 1 year ; 20xx to 20xx \n",
    "aired_years = [] \n",
    "for dates in anime_data['aired']: \n",
    "    if dates == \"Not available\":\n",
    "        aired_years.append(\"NaN\")\n",
    "    elif len(dates) > 4 and dates[0].isalpha():\n",
    "        start = dates.index(\",\") + 2 \n",
    "        year = dates[start:start+4] #gets the first year  \n",
    "        aired_years.append(int(year))\n",
    "    else:\n",
    "        aired_years.append(dates[0:3])\n",
    "anime_data['aired_year'] = aired_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anime_copied = anime_data.copy()\n",
    "print(\"Below are the first 5 rows of the dataset with the new column 'aired_year' \")\n",
    "anime_copied.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A future direction would be to look at how many anime is aired per year by using a histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WILL HAVE IMPLEMENTATION IN THE FUTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Correlation Between Popularity and Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popularity refers to how many users on MyAnimeList have that specific anime added into any list (ex: \"want to watch\", \"watching\", \"dropped\", \"finished\", etc.) under their account. Given that people often base their watching decisions off of word-of-mouth or online recommendations, higher exposure to an anime name might be what leads people to put the anime down on their list, thus indicating high popularity. In addition, the titles that get passed around tend to be titles that were well-received. Consequently, we predict that higher popularity should be somewhat positively correlated with the anime's ranking, such that a low digit in popularity corresponds with a low digit in ranking. This next section will attempt to analyze this relationship:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot of Popularity and Rank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(anime_data['popularity'], anime_data['ranked'], alpha = 0.1)\n",
    "plt.xlabel(\"Popularity\") and plt.ylabel(\"Ranked\") and plt.title(\"Anime Popularity v. Rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_rank_correlation = anime_data['popularity'].corr(anime_data['ranked'])\n",
    "print(\"Correlation between Anime Popularity and Rank: {:.2f}\".format(pop_rank_correlation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of The Number of Anime That Each Genre Has "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many anime in the dataset are tagged with more than one genre. Below, we hoped to analyze which genres are most common in anime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_data_copy = anime_data.copy()\n",
    "tags = anime_data_copy['genre'][0] \n",
    "tags = ast.literal_eval(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we found all the unique anime genres below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genre_list = []\n",
    "for anime_tags in anime_data_copy['genre']: \n",
    "    anime_tags = ast.literal_eval(anime_tags)\n",
    "    for i in range(len(anime_tags)):\n",
    "        if anime_tags[i] not in genre_list:\n",
    "            genre_list.append(anime_tags[i])\n",
    "print(\"List of anime genres: \" + str(genre_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Genre Counting Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we created a dataframe with the genre and count columns. We instantiated the counts to 0 for each genre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genre_count = pd.DataFrame(columns = ['genre', 'count'])\n",
    "genre_count['genre'] = genre_list\n",
    "genre_count['count'] = [0] * len(genre_list)\n",
    "genre_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for anime_tags in anime_data_copy['genre']: \n",
    "    anime_tags = ast.literal_eval(anime_tags)\n",
    "    for genre in anime_tags:\n",
    "        i = genre_list.index(genre)\n",
    "        genre_count['count'][i] = genre_count['count'][i] + 1 \n",
    "print(\"First few rows of new dataframe: \")\n",
    "print(genre_count.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Genre Counts from Most Counts to Least Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_count.sort_values(by = ['count'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging User Profiles CSV with User Reviews CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"profiles.csv\")\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the file, we cleaned the data of columns that we don't need: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users = users.drop(columns = ['birthday', 'link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we imported the reviews.csv: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"reviews.csv\")\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we got to merging the user reviews with the user profile: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user_reviews = pd.merge(users, reviews, on = \"profile\")\n",
    "user_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we looked at how many animes received reviews: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Animes that Received Reviews: \" + str(len(user_reviews['anime_uid'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the datasets\n",
    "anime_recent = pd.read_csv(\"MAL_anime_sept20.csv\")\n",
    "user_watch = pd.read_csv(\"user_watches_sept20.csv\")\n",
    "userID = pd.read_csv(\"user_watches_sept20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID = userID.drop(columns=[\"join_date\", \"last_scraped_date\"])\n",
    "userID.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data limitations\n",
    "1. Some user data like birthdate and gender are missing or incorrect due to self-reporting of gender and birthdate.\n",
    "2. Because we are merging and using two different datasets, one 3 months more recent than the other (but missing information on ratings, for example), the more recent observations may be missing information in some columns\n",
    "3. Popularity data doesn't show which subset of \"Anime List\" it is in\n",
    "4. Some anime dont have their air date, some of them only have the year and not the month\n",
    "5. When plotting correlation, there is a ton of aggregates which makes the graph very difficult to interpret. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for reviewers\n",
    "--------------------------------------------------------------------\n",
    "1. Are we allowed to set two separate datasets even after merging datasets? For example, one has anime information, the other has solely user information and we want to perform separate analyses on them (they can't be merged)\n",
    "2. How do we use an API? \n",
    "3. How many research questions can we explore?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
